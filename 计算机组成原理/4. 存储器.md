
# 概述

## 存储器分类

按存储介质分类, 存储器可分为:
- 半导体存储器
- 磁表面存储器, 如: 磁盘, 磁带, 磁鼓
- 磁芯存储器, 用磁环存储数据, 磁环中穿过驱动线和读出线
- 光盘存储器

按存取方式, 存储器可分为:
- <font color=red><b>RAM</b></font> Random Access Memory, 随机存储器. 其中任何一个存储单元的内容都可以随机存取, 存取时间与存储单元的物理位置无关. RAM又分为SRAM(静态)和DRAM(动态). SRAM利用触发器寄存, DRAM利用电容寄存.
- <font color=red><b>ROM</b></font> Read Only Memory, 派生出PROM, EPROM, EEPROM. 后续发展出Flash Memory

另外还有串行访问存储器, 在读写操作室, 需要按照物理位置先后顺序进行寻址. 例如: 磁带. 磁盘也属于部分串行访问的存储器.


按在计算机中的作用分类, 可分为:
- <font color=red><b>主存</b></font>: 可以直接与CPU交换信息.
- <font color=red><b>辅存</b></font>: 不直接与CPU交换信息, 用于存放暂时不用的程序和数据.
- <font color=red><b>缓存</b></font>: 用在两个速度不同的部件之间起缓冲, 例如CPU和主存之间.

时至今日, 存储器的分类与作用为:

主存: DRAM
辅存: Flash Memory, 磁盘
缓存: SRAM

存储器的层次结构为:

$$
\begin{array}{c}
寄存器 \\
\Downarrow \\
缓存 \\
\Downarrow \\
主存 \\
\Downarrow \\
辅存
\end{array}
$$

越下层的存储器速度越慢, 容量更大, 成本更高.

理论上CPU可以直接和主存进行数据交换, 但是几乎从不这么做. 
现代计算机的CPU都是通过多级Cache获取数据, 而不会直接访问主存, 这是由于访问主存速度很慢, 可能会影响上百个CPU时钟周期.

主存和缓存之间的数据调动是硬件自动完成的, 对程序员透明.

<font color=red><b>MMU</b></font>通常在CPU与主存之间, 其核心职能为**虚拟内存管理**. 负责转换虚拟地址空间和物理地址空间: 
1. 地址翻译: 根据页表将虚拟地址翻译成物理地址. 使每个进程都认为自己独占一整片内存空间, 但实际可以映射到不同物理页.
2. 权限检查
3. 页异常管理

虚拟内存是围绕**页**展开动作的. 页是虚拟地址空间与物理地址空间映射的最小块. 
页表记录了虚拟页和物理页的映射关系.
常见页大小为4KB.

程序始终访问虚拟地址, 真实物理地址对程序透明. 每一次程序对数据的访问, MMU都会介入地址翻译.
现代CPU会在MMU内放一个小Cache (Translation Lookaside Buffer, TLB), 若命中, 则可以直接跳过页表查询.
对于CPU的一次数据访问, MMU会:
1. 查询 TLB, 若命中则直接得到物理地址.
2. Cache查找
3. DRAM查找
4. Flash查找


# 主存

主存的MDR通常设计为与CPU机器字长相等宽度. MAR通常设计为和地址总线宽度相等.

MDR和MAR都在CPU内部, 现代CPU通过Address Generation Unit和Load/Store Buffer取代了MDR和MAR.

现代主存使用<font color=red><b>DDR SDRAM</b></font>. 抽象的MAR和MDR之后, 输入到内存控制器中, 由内存控制器, 通过DDR PHY连接到内存.

内存上有被动逻辑执行单元, 用来译码地址, 解析命令, 对存储单元进行操作.

SRAM是使用触发器电路的存储结构.

DRAM是使用电容的存储结构. 由于电容中的电荷会消失, 因此DRAM需要进行刷新, 来保证数据的存储. 刷新周期通常为几ms至几百ms.
DRAM有三种刷新方式:
- 集中刷新: 在规定的一个刷新周期内, 对全部存储单元集中一段时间进行逐行刷新. 刷新过程中需要停止读/写操作. 不能进行读/写的时间称为访存死区, 所占比率称为死时间率.
- 分散刷新: 将每一个存取周期均划分成读写阶段和刷新阶段, 在刷新阶段对存储芯片进行刷新. 没有死区, 但是会延长存取周期, 造成浪费.
- 异步刷新: 按行数将刷新动作平分到整个刷新周期, 对于每一段来说是集中刷新, 对于整体来说是分散刷新. 将刷新安排在CPU指令译码阶段, 避免死区问题.

TTL和CMOS的主要区别:
TTL的核心器件是BJT, 是电流控制型器件, 需要电阻限制电流, 功耗较大.
CMOS的核心器件是MOSFET, 是电压控制型器件, 几乎不需要电流, 功耗极低.

PROM在每位存储单元内有熔丝, 熔丝断与未断用于存储数据.

EPROM和EEPROM是通过浮动栅型MOSFET, 利用浮动栅实现0和1的存储. 浮动栅被绝缘层隔绝, 存储的电荷不能轻易移动, 不会轻易消失.

Flash 也使用浮动栅型 MOSFET 存储数据. Flash 的擦除是通过块擦除的模式.
NOR Flash 每个存储单元有独立的位线, 可以随机访问单个字节. NAND Flash 按块读写.
Flash 通过精确控制浮动栅中电荷量的不同, 区分出多个电压阈值区间, 从而在一个单元中存储多位信息, 即: SLC, MLC, TLC, QLC.


## 存储器与CPU的连接

由于单片存储芯片容量有限, 因此通常需要将若干存储芯片组合, 称为存储容量的扩展, 分为位扩展与字扩展.
- 位扩展: 增加存储字长, 例如 2片 1K×4 bit 的芯片构成 1K×8 bit 的存储器.
- 字扩展: 增加存储器字数量, 例如 2片 1K×8 bit 的芯片构成 2K×8 bit 的存储器.
- 字, 位扩展: 组合以上两种方式.

存储器与CPU连接包括地址线, 数据线, 控制线(读/写命令线, 片选线)

## 汉明码

汉明码是一种检错纠错的编码, 具有1位纠错能力.

<font color=red><b>汉明距离</b></font>是两个等长传对应位置不同字符的数量.
<font color=red><b>最小码距</b></font>是编码中任意两个有效码字之间的最小汉明距离.
有如下公式:

$$
d-1 = e+c
\quad (e\geq c)
$$

其中 $d$ 是最小码距, $e$ 是检错位数, $c$ 是纠错位数. 
增加冗余码可以提高最小码距, 提升纠错能力, 会降低码率. 
将上述公式变换:

$$
\begin{array}{l}
要检测\ e\ 个错误: d \geq e + 1 \\
要纠正\ c\ 个错误: d \geq 2c + 1
\end{array}
$$

汉明码通常表示为 $(n,k)$ 码, 其中:
- $k$ : 信息位的位数, 即原始数据长度
- $r$ : 校验位的位数
- $n$ : 总长度, $n = k + r$ 

对于纠正 1 bit 错误, 需要的校验位数 $r$ 必须满足 $2^r \geq k+r+1$ 或 $2^r \geq n + 1$ .

汉明码被设计为能够判断数据中的哪一位出现错误. 对于总长为n的码字, 错误可能发生在n个位置中的任意一个, 也可能不发生错误, 即一共 $n+1$ 种状态. 

汉明码的核心思想是用 $r$ 个校验位, 生成一个 $r$ 位的二进制数, 这个数即错误地址.

由此可见, 对于能够表示错误发生位的前提是, $2^r$ 一定大于等于总码字长 $n+1$ .

例如: 校验位数 $r = 3$ , 则:
- $0b000 = 0$ 表示无错误.
- $0b001 = 1$ 表示第 1 位出错.
- $\cdots$
- $0b111 = 7$ 表示第 7 位出错.

可见, 当 $r=3$ 时, 最多可以处理7位数据的纠错需求.

7 位数据中, 去除校验位的 3 位, 剩余的 4 位是原本的实际数据位.

在以上基础前提要求下, 汉明码通过精心安排校验位的检测范围, 巧妙地做到了伴随式 $S$ 的值与错误发生的位序号完全一致.

编码规则为:
- 将 $r$ 个校验位 $P_1, P_2, \cdots, P_r$ 放在位序号 $1,2,4,\cdots,2^{r-1}$ 上 (从 $1$ 开始记) . 
- 将每个校验位 $P_i$ 定义为对所有位序号中包含 $2^{i-1}$ 的位进行校验 (通常是奇偶校验) .

以 $(7,4)$ 码为例:

$$
\begin{array}{c|c|c}
\hline
位序号 & 二进制分解 & 对应校验位 \\
\hline
1 & 001 = 4^0 + 2^0 + 1^{\color{red}1} & 受P_{\color{red}1}检验 \\
\hline
2 & 010 = 4^0 + 2^{\color{red}1} + 1^0 & 受P_{\color{red}2}检验 \\
\hline
3 & 011 = 4^0 + 2^{\color{red}1} + 1^{\color{red}1} & 受P_{\color{red}1}, \ P_{\color{red}2}检验 \\
\hline
4 & 100 = 4^{\color{red}1} + 2^0 + 1^0 & 受P_{\color{red}3}检验 \\
\hline
5 & 101 = 4^{\color{red}1} + 2^0 + 1^{\color{red}1} & 受P_{\color{red}1}, \ P_{\color{red}3}检验 \\
\hline
6 & 110 = 4^{\color{red}1} + 2^{\color{red}1} + 1^0 & 受P_{\color{red}2}, \ P_{\color{red}3}检验 \\
\hline
7 & 111 = 4^{\color{red}1} + 2^{\color{red}1} + 1^{\color{red}1} & 受P_{\color{red}1}, \ P_{\color{red}2}, \ P_{\color{red}3}检验 \\
\hline
\end{array}
$$

假设第 $6$ 位出错, 对应二进制编码为 $110$ , 该位受 $P_2$ 和 $P_3$ 检验. 
则 $P_2$ 和 $P_3$ 检验到错误后变为 $1$ , $P_1$ 由于没有被影响, 因此保持 $0$ . 
此时伴随式 $S$ 的值为 $6$ , 与出错位序号相同, 据此进行纠错即可.

从上表可知:
- $P_1$ 覆盖第 $1,3,5,7$ 位.
- $P_2$ 覆盖第 $2,3,6,7$ 位.
- $P_3$ 覆盖第 $4,5,6,7$ 位.

将校验码与数据整合, 其结构为:

$$
\begin{array}{}
位序号 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\
内容 & D_4 & D_3 & D_2 & P_3 & D_1 & P_2 & P_1 \\
\end{array}
$$

校验位的任务是让其覆盖的所有位满足特定的奇偶性.

对于偶校验而言, 使用异或运算得到的校验位能够使一组位中, $1$ 的总个数为偶数, 即:

$$
偶校验位 = 覆盖信息位的异或和
$$

对于奇校验而言, 使校验位在偶校验的基础上取反, 即:

$$
奇校验位 = \overline{偶校验位} = \overline{覆盖信息位的异或和}
$$

由于偶校验更简单, 因此实际偶校验使用更广泛.

下面以偶校验 $(7,4)$ 码举一个实际案例.

$$
\begin{array}{}
位序号 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\
内容 & D_4 & D_3 & D_2 & P_3 & D_1 & P_2 & P_1 \\
数据 & 1 & 1 & 0 & - & 1 & - & - \\
\end{array}
$$

即待发送数据为 $1011$ . 分别计算各个校验位的值:

$$
\begin{array}{}
P_1 = 3_{位} \oplus 5_{位} \oplus 7_{位} = D_1 \oplus D_2 \oplus D_4 = 0 \\
P_2 = 3_{位} \oplus 6_{位} \oplus 7_{位} = D_1 \oplus D_3 \oplus D_4 = 1 \\
P_3 = 5_{位} \oplus 6_{位} \oplus 7_{位} = D_2 \oplus D_3 \oplus D_4 = 0
\end{array}
$$

最终计算得到汉明码为:

$$
\begin{array}{}
位序号 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\
内容 & D_4 & D_3 & D_2 & P_3 & D_1 & P_2 & P_1 \\
数据 & 1 & 1 & 0 & {\color{green}0} & 1 & {\color{green}1} & {\color{green}0} \\
\end{array}
$$

假设传输中第 $5$ 位发生翻转, 数据变为 $1110110$ , 重新计算伴随式 $S=C_3 C_2 C_1$ .

翻转后的数据为:

$$
\begin{array}{}
位序号 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\
数据 & 1 & 1 & {\color{red}1} & 0 & 1 & 1 & 0 \\
\end{array}
$$

$$
\begin{array}{}
C_1 = 1_{位} \oplus 3_{位} \oplus 5_{位} \oplus 7_{位} = 0 \oplus 1 \oplus 1 \oplus 1 = 1 \\
C_2 = 2_{位} \oplus 3_{位} \oplus 6_{位} \oplus 7_{位} = 1 \oplus 1 \oplus 1 \oplus 1 = 0 \\
C_3 = 4_{位} \oplus 5_{位} \oplus 6_{位} \oplus 7_{位} = 0 \oplus 1 \oplus 1 \oplus 1 = 1
\end{array}
$$

得到伴随式 $S=101b=5$ , 因此第 $5$ 位被翻转. 修正后可以得到正确的元数据.


汉明码仅能够进行1位纠错. 拓展汉明码可以进行多位检错, 例如 $(8,4)$ 码可以检测 2 位错误, 并且纠正 1 位错误.

两位即以上纠错码, 类似BCH码, 需要更复杂的编码解码机制, 其对应码距也更大.


## 提高访存速度

### 单体多字系统

对于连续存储在主存内的指令, 可以通过**单体多字**系统, 使用 1 个地址, 在一个存取周期内同步取出多个指令. 
例如, 单体四字结构中, 一次访存动作, 取回4个连续的指令.
为了实现单体多字, 数据总线宽度必须加宽, 例如原本是 64-bit 的标准单字, 为了实现单体四字, 数据总线必须扩宽到 256-bit .

现代设备框架中, 地址总线, 数据总线和控制总线的概念被模糊. 通常使用专用接口连接CPU和内存.
CPU内部通常继承了内存控制器 (原本在北桥芯片中), 通过DDR通道与内存相连.

Burst Mode, 即**突发模式**是体系中一种为了提升效率的带宽优化技术. 
Burst Mode 利用了两个传输过程的特点:
- 高延迟: DRAM内存访问的延迟 (从发出请求, 到第一个数据可用) 很高. 这是由于需要进行行地址选通 (RAS) 和列地址选通 (CAS) 等操作.
- 高带宽: 一旦DRAM内部操作完成, 内存可以以非常高的速度持续读出数据.

单体多字利用了高延迟和高带宽的特点, 付出 1 次高延迟的代价, 获得多分数据, 提高了带宽.

Burst Mode 的具体实现是通过控制总线上的不同命令实现的.

以下为 CPU 和 Cache 各自可以完成的工作:
- CPU 发起**单字存取**: 若数据 Hit 在 Cache 中, 则直接取走, 若 Miss , 则触发Cache的块传输流程, 发起 Burst Mode 从内存中取数据.
- Cache 发起**块传输**: 发起 Burst Mode 进行 Cache 行填充.


### 多体并行系统

多体并行系统是将主存分割成多个独立的, 可以并行工作的存储体. 存储体是交错组织的, 连续的地址会被分配到不同的存储体中. 

例如, 在 CPU 请求连续的 4 个数据时, 内存控制器可以同时向 4 个存储体 (假设有 4 个存储体) 发送请求, 虽然单独存储体延时不变, 但由于操作时并行的, 因此 CPU 依然可以在一个周期内接受来自不同体的 4 个数据, 从而使带宽增加. 

在内存颗粒内部, 多体并行体现为 Bank 级并行. 
内存控制器可以向同一颗粒中的不同 Bank 发送请求, 这允许在等待 1 个 Bank 完成其较长的行激活 (RAS) 操作时, 同步可以对另一个 Bank 进行列访问 (CAS) 操作, 提高单个芯片的利用率和吞吐.

另外, 双通道 DDR 也是多体并行系统的应用. 通过双通道, 可以使数据带宽翻倍.


## DDR

Double Date Rate SDRAM , 即**双倍数据率同步动态随机存储器**. 其数据传输速率为系统主频的 2 倍. DDR 在系统时钟的上升沿和下降沿都可以进行数据传输.

DDR 规定了一系列的标准, 包括:
- 存储介质类型: 规定了存储单元的基本电气特性和读写时序
- 接口 / 总线协议: 规定了内存颗粒与内存控制器之间通信的物理和逻辑协议, 包括数据, 地址, 控制线的数量, 电压, 以及时序. 定义了 CPU 内存控制器与内存模组的通信规则.
- PHY: 规定了物理层, 包括引脚设计, 阻抗匹配, 信号完整性要求, 电压, 传输方式等.
- 通信规范: 详细的时序参数, 传输机制等.

有一些参数可以影响 DDR 内存的传输速率.

- **数据传输速率**. 例如 DDR5-5600 , 表明数据传输速率为 5600MT/s . 
  根据 DDR 的双倍原理, 内存系统总线的实际时钟频率 ( DDR Clock 或 Base Clock ) 是传输速率的 $1/2$  , 即 2800 MHz . 该频率代表内存模块支持的最高速度. 实际运行速度受 CPU 内存控制器, 主板, BIOS影响. 
  内存时钟由 CPU 内部的 MC 驱动和控制, 实际由主板产生.
  内存速度并没有匹配上 CPU 的速度, 因此存在 Cache .

- **内存时序**. 内存时序通过一系列参数表示: CL-tRCD-tRP-tRAS.
	- <font color=red><b>CL</b></font> (CAS Latency, Column Address Strobe Latency), 即 CAS 延迟. 指从内存控制器发出读取数据命令 (CAS信号) 到数据开始从 DRAM 的 I/O 引脚传出, 所需要的最小等待周期数. CL 是最常见的参数, CL 越小, 内存响应越快.
	- <font color=red><b>tRCD</b></font> (Time Row to Column Delay), 即 RAS 到 CAS 延迟. 指从激活一行 (发出 RAS 信号) 到发出列读取命令 (CAS 信号) 所需的最小等待周期数. 这是因为, 一行被激活后, 需要时间将数据从存储单元传输到感应放大器中稳定, tRCD就是保证稳定性的延迟.
	- <font color=red><b>tRP</b></font> (Time Row Precharge), 即行预充电时间. 指从关闭 (预充电) 当前行到激活新行所需要的最小等待周期数. DRAM 访问完 1 行后, 必须对该行进行预充电 (恢复平衡状态) , 才能激活下一行. 预充电本质就是数据恢复 (重写) , 恢复被读操作破坏的数据. 另外需要将位线恢复到参考电压, 以备让放大器检测新行的电荷.
	- <font color=red><b>tRAS</b></font> (Time Row Active Strobe), 即行激活时间. 一行被激活 (发出 RAS 信号) 到它必须被关闭 (预充电) 之间的最短时间. 这是为了防止数据丢失, 确保 DRAM 内部操作能够完成的最小时间, 若 tRAS 太短, DRAM 可能无法完成内部操作.

一个完整的行数据访问, 然后切换到新行的操作顺序如下:
1. 激活: MC 发出 RAS 信号, 要求进行行访问, tRAS开始计时.
2. 读写: MC 发出 CAS 信号, 属于 tRAS 内部过程, 进行数据读写.
3. 关闭 (预充电): 当满足 tRAS 后, MC 发出预充电命令, tRP 开始计时, tRAS结束.
4. 新激活: tRP 满足后, MC 发出下一个 RAS 信号, 激活新行, 开启下一个循环.

当触发 Burst Mode 且数据在同一行时, 进行一次 RAS 后, 可以进行多次 CAS , 完成后再进行 Precharge.

DRAM 的刷新内存指令也是由 MC 发出的.

MC 会将 MMU 给出的物理地址进行逻辑划分, 分为 3 个部分: Bank 地址, 行地址, 列地址.
随后, MC 会分时发送地址:
- 发送 Bank 地址和行地址, 发出 RAS 信号.
- 发送列地址, 发出 CAS 信号.

MC 会通过读取内存的 SPD (Serial Presence Detect) 信息 (通过低速总线, 如 $I^2C$ ) , 获取内存的详细信息, 包括总容量, 颗粒配置 (Bank 数), 时序参数等.

在开机识别信息后, MC 会计算总 Bank 数, 会根据最佳性能原则, 如交错寻址, 将物理地址划分并映射到整个物理内存可用的 Bank 或 DIMM (Dual Inline Memory Module, 双列直插内存模块, 即两面金手指不互通, 有双倍通道) 上.

DRAM内部会负责译码与定位, 会将对应地址输出为具体信号线, 激活对应的行列.

双通道内存是一种多体并行系统的应用.

对于多通道内存, 现代架构是通过星型拓扑, 即独立内存通道进行连接的. 
每个通道都拥有独立的数据, 地址, 控制信号. 对于双通道而言, MC 可以同时激活通道 A 和通道 B , 实现并行访问.
此外, CPU 可能支持双通道, 但主板上有 4 槽位, 此时 1, 3 可能属于通道 A, 而 2, 4 可能属于通道 B .


## 内存相关的控制设备

<font color=red><b>MMU</b></font> (Memory Management Unit, 内存管理段元)

MMU 在 CPU 内部. 
核心职责为虚拟地址和物理地址的转换.
关键机制依赖于页表 (Page Table) 和快表 (Translation Lookaside Buffer, TLB)


<font color=red><b>MC</b></font> (Memory Controller, 内存控制器)

现代 MC 大多在 CPU 内部, 早期位于北桥.
核心职责为协议翻译和时序控制, 是 CPU 侧的总线接口.
MC 接受 CPU 的读写请求, 以及 MMU 提供的物理地址, 将这些请求翻译成 DDR 协议下规定的电信号和时序. MC还管理数据总线和地址总线, 确保数据能够以 Burst 模式高效传输.


**内存颗粒**

内存颗粒内部也有对应的逻辑电路, 包括地址解码器, 读写缓冲器, 时序和逻辑控制器等.
内存颗粒按照 DDR 协议的要求, 完成数据的存取, 刷新等操作.


**Cache Controller**

Cache Controller 是所有数据和指令存取的第一站, 决定了是否需要访问内存.
负责检查 CPU 要求的地址是否命中, 若 Cache Miss 则会发起一个块传输请求给 MMU 和 MC , 要求从主存中拉取一整个 Cache Line.


# Cache

通常 I/O 对主存请求的优先级高于 CPU , 会出现 CPU 等待 I/O 访存的问题, 降低 CPU 工作效率.
此外, 主存速度始终跟不上 CPU 的速度, 也造成主存与 CPU 速度不匹配. 
因此, 需要 Cache 缓解二者之间的速度差异.

Cache 的可行性, 是由于 CPU 在一定时间内从主存存取指令或存取数据时, 通常都是对主存的局部区域进行访问. 这是由于数据和指令在主存内通常都是连续存储的. 
此外, 部分数据和指令会被多次调用, 如子程序, 循环程序, 函数等.
由于指令和数据在主存中的地址分布不是随机的, 即**程序访问的局部性原理**, 引入采用 SRAM 的 Cache 可以缓解主存和 CPU 之间的速度差异.

## Cache 的工作原理

主存由 $2^n$ 个可编址的字组成, 每个字有唯一的 $n$ 位地址. 
为了与 Cache 映射, 将主存与 Cache 都分成若干<font color=red><b>块</b></font>, 每个块内包含若干个字, 使块大小相同, 即块内的字数相同. 
将主存的地址分成两段, 高 $m$ 位表示**块地址**, 低 $b$ 位表示**块内地址**, $2^m$ 表示主存的块数.
Cache 地址同样分成两段, 高 $c$ 位表示缓存**块地址**, 低 $b$ 位表示**块内地址**, $2^c$ 表示 Cache 的块数.
$2^c << 2^m$ . $2^b$ 反映了块的大小, 称为块长.

任意时刻, 均有一些主存块处于 Cache 块中.

CPU 请求某主存字时, 存在两种可能:
- Hit, 字已在 Cache 中, 直接访问.
- Miss, 字不在 Cache 中, 将该字所在字块一次调入 Cache 中.

Cache 中的每一个块设有一个标记, 用于记录当前存放的是哪一个主存块, 对应主存的高 $m$ 位块地址.

Cache 的块数与块长是影响效率的重要因素. 用命中率来衡量 Cache 的效率, 命中率是指 CPU 访问的信息已在 Cache 中的比率. 

$$
命中率\ h = \frac{N_c}{N_c + N_m}
$$

- $N_c$ 命中次数.
- $N_m$ 未命中次数.

$$
Cache-主存系统平均访问时间\ t_a = 
ht_c + (1-h)t_m
$$

- $t_c$ Cache 访问时间.
- $t_m$ 主存访问时间.

通常, Cache 容量越大, 命中率越高, 但当 Cache 达到一定大小后, 命中率不会有进一步的明显提升. 
块长与命中率之间的关系更为复杂. 随着块长增加, 由于局部性原理, 临近的字可能也会被访问, 因此块长增加可将更多有效字存入缓存, 提升命中率. 但若持续增加, 则可能被过长的块替换掉有用的数据, 造成命中率降低.

Cache 的基本结构包括:
- 存储体: 用于与主存交换数据, 访存优先级最高.
- 地址映射变换机构: 用于将 CPU 提供的主存地址, 转换为 Cache 地址, 即块号映射.
- 替换机构: 当 Cache 已满, 替换机构按一定的替换算法确定从 Cache 中将某些块移回主存, 将新块移入 Cache .

在写数据时, 需要保持 Cache 和主存的数据一致, 有如下几种方法:
- 写直达法 (Write-through), 也称存直达法 (Store-through), 即写操作时, 数据同时写入 Cache 和主存, 保证了数据始终一致, 但增加了访存次数.
- 写回法 (Write-back), 也称为拷回法 (Copy-back), 即写操作时, 数据仅写入 Cache, 当 Cache 块即将被替换时, 才将数据写回主存. 
  写回法中, 块有两种状态: Clean 和 Dirty. 每一个块都需要增加一个标记位, 用来记录状态. Cache 替换时, Clean 的块不需要写回主存, Dirty 的块需要写回主存.

目前的 CPU 大多采用多级缓存的方案.

另外, Cache 还分为统一缓存和分立缓存.
- Unified Cache 将指令和数据存储在同一块缓存中. L2 和 L3 通常采用统一缓存.
- Split Cache 将指令和数据分成不同的缓存. L1 通常采用分立缓存.

使用分立缓存可以并行地在 1 个时钟周期内, 同时获取指令和数据, 防止竞争端口.
分立缓存也可以更好的支持流水线操作.


<font color=red><b>流水线执行</b></font> (Pipelining) 

流水线执行是现代 CPU 提升 IPC 的核心技术.
早期 CPU设计中, 一条指令必须完全执行完毕后, 下一条才能开始执行, 称为**串行执行**.
流水线执行通过将指令的执行过程分解为一系列独立的串行连接的阶段 (Stage), 允许阶段并行工作.

例如经典的 RISC (ARM就是 Advanced RISC Machine) 设计中, 指令执行分解成 5 个主要阶段:

|  **阶段**   |              **英文缩写**               |         **作用**          |                                **描述**                                |
| :-------: | :---------------------------------: | :---------------------: | :------------------------------------------------------------------: |
| **1. 取指** | $\text{IF}$<br>(Instruction Fetch)  |   从**内存/缓存**中读取下一条指令    |                   这一阶段 $\text{CPU}$ 只需要知道下一条指令的地址                    |
| **2. 译码** | $\text{ID}$<br>(Instruction Decode) |  **解析**指令, 确定所需的操作和操作数  |                            从寄存器中读取所需的操作数                             |
| **3. 执行** |      $\text{EX}$<br>(Execute)       |      **执行**算术或逻辑运算      |                   使用算术逻辑单元 $\text{ALU}$ 计算结果或内存地址                    |
| **4. 访存** |   $\text{MEM}$<br>(Memory Access)   |     访问**数据缓存/主内存**      | 如果是加载 $\text{Load}$ 指令, 从内存读取数据;<br>如果是存储 $\text{Store}$ 指令, 将数据写入内存 |
| **5. 写回** |     $\text{WB}$<br>(Write Back)     | 将指令的最终结果**写入**到**寄存器**中 |                                完成指令执行                                |

从 RISC 的阶段可以看到, 若指令串行执行, 则 IPC 一定小于 1 .

流水线有几种情况, 会导致流水线执行受阻, 会降低 CPU 性能.
1. 结构冒险: 多个指令在同一周期访问统一硬件资源.
2. 数据冒险: 后一条指令需要输入的数据, 是前一条指令尚未产生的结果.
3. 控制冒险: 流水线遇到了分支指令, 在分支指令执行完成前, 下一条执行的指令地址未知.

现代 CPU 可以通过超标量和乱序执行提升 IPC , 使 IPC 可以达到 2~5 甚至更高.
- <font color=red><b>超标量</b></font>: 单核 CPU 一次可以执行多条指令
	- 多个执行单元: CPU 核心内部包含多个独立的执行单元, 例如 2~4 个ALU, 2~3 个浮点向量单元, 2~4 个访存单元.
	- 并行发射: 一个时钟周期内, CPU 的 Scheduler 可以同时将多条不互相依赖的指令分配给不同的空闲执行单元, 使其同时执行.
	 实现一个周期内同时开始多条指令的 EX 阶段, 使 IPC 超过 1 .
- <font color=red><b>乱序执行</b></font>: 超标量需要复杂的乱序执行机制来喂饱所有执行单元.
	- CPU 会查看程序中顺序排列的指令流.
	- 若发现某条指令与前序指令没有数据依赖关系, 则将其提前, 并行执行.
	- CPU 确保最终结果严格与顺序执行相同.

此外, CPU 还利用 <font color=red><b>Vectorization</b></font> 和 <font color=red><b>SIMD</b></font> 技术进一步提升 IPC.

SIMD (Single Instruction, Multiple Data) 即单指令流多数据流.
将 CPU 寄存器设计成超宽的, 一条 SIMD指令可以同时对寄存器中的所有数据元素执行相同的操作.
在宏观视角中, 相当于同时完成了多个独立的操作.


## Cache-主存地址映射

Cache 与主存可以通过多种方式进行地址映射.
- **直接映射** (Direct mapped): Cache 与主存间建立固定的映射关系 $i = j \mod C$ 或 $i = j \mod 2^C$ . $i$ 为缓存块号, $j$ 为主存块号, $C$ 为缓存块数. 
  直接映射的问题是: 主存内的每个主存块只能固定地对应某个缓存块. 若程序恰好重复防伪对应同一缓存块的不同主存块, 就需要不停进行块替换, 降低命中率.
- **全相联映射** (Fully-associative): 允许主存中每一字块映射到 Cache 中的任意一块位置上.
- **组相联映射** (Set-associative): 全相联映射和直接映射的折中.

Cache 中的**行**和**块**通常是等价的, 块是逻辑单位, 行通常表示 Cache 中用来容纳一个块的容器.

CPU 的主存地址通常被分成 3 部分:

$$
主存地址 = \text{块标识 Tag} + \text{组索引 Index} + \text{块内偏移 Offset}
$$

- 块内偏移 Offset: 用于定位数据块内的具体字节, 其长度由块长决定, 若块长为 $2^B$ byte, 则 Offset 占 $B$ 位.
- 组索引 Index: 用于定位数据位于 Cache 内的**组**, 由 Cache 内的组数决定.
- 块标识 Tag: 用于唯一标识主存中的哪个块驻留在 Cache 中. Tag 越长, 主存容量越大.

以下案例用以区分三种 Cache - 主存地址映射方案
- 主存总容量: 4GB 对应 32-bit 地址.
- Cache 总容量: 16 KB
- Cache 块大小: 64 Byte

从块大小可以计算得到, 块内偏移 Offset 应该为 $\log_2(64) = 6$ 位.

**直接映射**
主存中的每个块只能映射到 Cache 中的**唯一**一行.
计算行数: $\text{16 KB} / \text{64 Byte} = \text{256}$ 行.
Index 宽度: $\log_2(256) = 8$ 位.
地址结构:

$$
\text{32 bit} = 
\underset{\text{Tag}}{\underbrace{\text{18 bit}}} \ + \ 
\underset{\text{Index}}{\underbrace{\text{8 bit}}} \ + \ 
\underset{\text{Offset}}{\underbrace{\text{6 bit}}}
$$
例如:

| **主存块地址 (32 位)**        | **Index (8 位)** | **Cache Line 编号** | **结论**              |
| ----------------------- | --------------- | ----------------- | ------------------- |
| $\text{A (0x00010000)}$ | $00000000_2$    | $\mathbf{0}$      | 映射到第 $\mathbf{0}$ 行 |
| $\text{B (0x00014000)}$ | $00000000_2$    | $\mathbf{0}$      | 映射到第 $\mathbf{0}$ 行 |
| $\text{C (0x00018040)}$ | $00000001_2$    | $\mathbf{1}$      | 映射到第 $\mathbf{1}$ 行 |

因为主存中的每个块只能映射到固定的一行, 因此查找时, 只需要对比对应的 1 行的 Tag 即可, 若没有命中, 则需要重新从主存中传输块.

**全相联映射**
主存中的任何块都可以放置在 Cache 中的任何行.
没有 Index 字段, 因为数据可以放在任意位置, 不需要组索引.
地址结构:

$$
\text{32 bit} = 
\underset{\text{Tag}}{\underbrace{\text{26 bit}}} \ + \ 
\underset{\text{Offset}}{\underbrace{\text{6 bit}}}
$$

查找时, 需要比对全部的 256 个块的 Tag, 比较浪费时间, 耗电较高, 通常仅用于 L1 缓存中非常小的部分, 如 TLB.

**组相联映射**
性能和成本的折中方案, 是现代 CPU 的主流选择.
将 Cache 划分成 $S$ 个组, 每组有 $E$ 行. 主存块先映射到唯一组, 然后可以在该组内映射到任意 1 行.
假设采用 4-way 组相联, 即 $E=4$ . 即每组含有 4 行, 映射时可选映射到 4 行中的任意一行.
组数为 $256/4=64$ .
地址结构:

$$
\text{32 bit} = 
\underset{\text{Tag}}{\underbrace{\text{20 bit}}} \ + \ 
\underset{\text{Index}}{\underbrace{\text{6 bit}}} \ + \ 
\underset{\text{Offset}}{\underbrace{\text{6 bit}}}
$$

使用组相联时, 主存块对应 Cache 中的一个 Set . 使得可以从 Set 中选取任意一行进行填充, 若 Set 全满, 则需要执行替换算法进行块替换.
在访问时, 只需要比较 Set 中的全部 Tag, 而不需要比较整个 Cache, 因此速度较全相联有大幅提升, 此外也有远优于直接映射的灵活性.


## 替换策略

当新的主存块需要调入 Cache, 而其可用空间被占满时, 需要替换掉原有 Cache 数据.
- 对于直接映射的 Cache, 主存块只能存储于唯一的 Cache 块中, 因此策略简单.
- 对于组相联和全相联映射, 主存可以写入 Cache 的若干位置, 此时需要选择替换的块. 
  理想算法是将未来很少用到, 或间隔很久才会用到的块进行替换, 实际较难做到, 通常有如下几种策略:
	1. FIFO: 将最早存入 Cache 的字块替换, 容易实现, 但没有根据访存的局部性原理, 因此对命中率提升没有帮助.
	2. LRU (Least Recently Used) 算法: 记录各字块的使用情况, 确定出近期最少使用的字块进行替换, 代价大, 通常使用简化方法, 例如记录每个块的最近一次使用时间. 命中率有提升.
	3. 随机法: 随机选择一个块进行淘汰. 实现最简单, 速度最快, 某些难以预测的模式下, 效果可能优于 FIFO.

全相联映射通常选用 LRU 或 Random 法.
组相联映射通常选用 LRU 法.


# 辅存

磁表面存储器是在不同形状载体表面涂有磁性材料层, 工作时, 靠载磁体高速运动, 由磁头在次蹭上进行读写, 信息的轨迹称为**磁道**.

磁表面存储器的技术指标包括:
- **记录密度**
- **存储容量** 存储容量包括非格式化容量 (可利用磁化单元总数) 和格式化容量 (按特定记录格式可存储数据总量).
- **平均寻址时间** 分为两部分, 磁头寻找磁道时间, 磁头寻找目标区段时间.
- **数据传输率** 与记录介质的移动速度相关
- **误码率** 磁表面出错概率

磁表面存储器的写入过程是通过写线圈, 产生磁场, 将介质顺序磁化. 充磁方向不同代表不同信息.
读出时, 运动的磁表面会在磁头读线圈中产生感应电动势. 不同的感应电流方向代表不同信息.

<p align="central">
<img src="https://media4.open.com.cn/L603/fushi/0903/jisuanjzcyl/web/lesson/char4/image/s57.gif" width="70%">
</p>

磁记录方式, 即编码方式, 是按某种规律将信息转换成磁表面对应的磁化状态. 常用的磁化记录方式有 6 种:
1. 归零制 (RZ): 写 1 通正向脉冲, 写 0 通反向脉冲. 两位信息间电流归零.
2. 不归零制 (NRZ): 始终有电流, 不是正向, 便是反向.
3. 见 1 翻不归零制 (NRZ1): 写 1 使翻转, 写 0 时不变.
4. 调相制 (PM): 写 0 和写 1 相位差180°, 即上升沿和下降沿.
5. 调频制 (FM): 调节变化频率, 写 0 时, 电流不变, 写 1 时, 电流翻转. 1 是 0 的翻转频率的 2 倍.
6. 改进型调频制 (MFM): 相较 FM 减少翻转次数.


<font color=red><b>硬磁盘</b></font> (HDD)

**磁头**可分为固定式与移动式.
**磁盘**可分为可换磁盘和固定磁盘.
**磁盘数量**可分为单磁盘和多磁盘.

硬磁盘存储器由**磁盘驱动器**, **磁盘控制器**和**盘片** 3 部分组成.

**磁盘驱动器**主要包括主轴, 定位驱动, 数据控制 3 部分.
主轴受传动机构控制, 高速旋转磁盘组. 音圈电机带动磁头做径向运动.  
定位驱动是闭环自控系统, 负责定位运动到准确的磁道.
数据控制部分负责数据转换及读写控制操作.

**磁盘控制器**接入主机总线, 接受命令, 将其转换成驱动器控制命令, 实现主机和驱动器之间的数据格式转换和传送, 控制驱动器的读写.

**盘片**是数据存储的载体. 常见尺寸为 3.5 英寸和 2.5 英寸. 磁盘的表面是均匀的, 不存在物理意义上的划分.

磁盘可以通过 RAID 的方式, 使用并行化的方案提升速度.

一个多盘的磁盘组, 可以看做是多个柱面组构成的存储系统, 不同盘的相同半径位置处视作同一圆柱面, 磁头的一次定位, 刚好可以访问相同的柱面. 
柱面个数为磁道数, 柱面号即**磁道号**, 磁头号为**盘面号**.
盘面分为若干**扇区**, 每条磁道分为若干**扇段**. **扇段是磁盘寻址的最小单位**.

定长记录格式中, 寻址通过磁道号, 盘面号, 扇段号进行寻址. 若不满扇段大小, 则剩余空间留空.

不定长记录格式中, 数据长度由计数器 DL 给定.

现代磁盘的存储密度非常高, 一个磁道可能包含 $10^4\sim10^5$ 个扇区, 若单个扇区 4 KB, 则可存储几百 MB 的数据.

磁道切换是HDD主要延迟来源之一. 跨磁道读写的延迟来源于寻道延迟和旋转延迟.


<font color=red><b>软磁盘</b></font> (FDD)

DOS系统中的 A 盘默认分配给第一个软盘驱动器, 通常是 3.5 寸软盘.
B 盘默认保留给第二个软盘驱动器.
C 盘开始分配给第一个硬盘驱动器.

软盘与硬盘结构类似. 软盘的盘片通常是几十µm的聚脂薄膜, 表面涂有 2.3~3 µm的磁层.

磁带与磁盘类似

## 循环冗余校验码 (CRC)

Cyclic Redundancy Check, CRC 可以发现并纠正信息在存储或传输过程中出现的多位错误代码.
CRC 码是基于模 2 云端而建立编码规律的校验码. 模 2 运算的特点是不考虑进位和错位的运算.

<font color=red><b>模运算</b></font>

模运算即求余数运算, 典型应用为 24 小时制时间换算.
模运算将无限的整数映射到一个有限的集合. 应用于循环计数, 哈希函数和公钥加密等.

模运算有<font color=red><b>同余性质</b></font>. 同余说的是两个数对于某个模运算而言是同类的, 是等价物, 即忽略了整数倍的部分, 仅关注余数.

a 同余于 b 模 n 记作:

$$
a\equiv b \ (\text{mod}\ n)
$$

对于上式的 a 和 b 有:

$$
a-b = k \cdot n, \ k\in\mathbb{Z}
$$

模运算加法满足:

$$
(a+b)(\text{mod}\ n) = \Big[ a(\text{mod}\ n) + b(\text{mod}\ n)\Big](\text{mod}\ n)
$$

模运算乘法满足:

$$
(a\cdot b)(\text{mod}\ n) = \Big[ a(\text{mod}\ n) \cdot b(\text{mod}\ n)\Big](\text{mod}\ n)
$$

对于模 2 运算, 其结果仅可能为 0 或 1.

计算机中主要关注二进制数的模 2 运算, 其余数字本质上做模 2 运算也只和其最低位相关.

模 2 加法与模 2 减法是等价的, 效果等同于异或, 相同为 0, 不同为 1:

$$
(a+b)(\text{mod}\ 2) = a \oplus b
$$

模 2 乘法效果等同于逻辑与:

$$
(a \cdot b)(\text{mod}\ 2) = a \land b
$$

模 2 除法与乘法效果相同:

$$
(a / b)(\text{mod}\ 2) = a \land b
$$

CRC的核心步骤是通过模 2 除法计算余数, 余数通过拼接得到 CRC 码.

CRC将待传输信息编码为多项式 $M(x)$ , 另外有一个生成多项式 $G(x)$ .
若 $G(x)$ 有 $k+1$ 位, 则需要计算的 CRC 校验码为 $k$ 位. 
CRC 校验码的计算步骤为:
1. 原始数据左移 $k$ 位, 空位补 $0$ .
2. 补 $0$ 后数据对生成多项式进行模 2 除法, 获得余数.
3. 将余数补 $0$ 到 $k$ 位后, 拼接到原数据后, 即得到 CRC 码.

例如, 原数据为`0b101001`, 生成多项式为`0b10011`.
1. 将原数据左移 $4$ 位, 得到 `0b1010010000`.
2. `0b1010010000`对`0b10011`做模 2 除法, 得到商 (不关心) `0b101110`和余数`0b10`.
3. 将余数补 $0$ 后, 拼接得到 CRC 码: `0b1010010010`.

将收到的循环校验码, 用约定的生成多项式除, 若无错误, 则余数应为 $0$ , 若某一位出错, 则余数不为 $0$ . 不同的出错位, 余数不同.

CRC 校验码有一个重要特性: 
余数的**循环性**. 
将循环码循环左移, 并除以生成多项式, 重复该操作, 新余数能循环到最初的余数, CRC 由此得名.

无论是哪一位出错, CRC 均需要将出错位循环左移到第 $1$ 位后进行纠正.

本质上, 对于例如 $(7,4)$ 这样的循环码, $3$ 位校验位, 余数也为 $3$ 位, 可以覆盖 $7$ 位数据中, 任意 $1$ 位的出错. 若余数为非 $0$ , 通过查表也可以判断出错的位数.

但 CRC 可以不通过查表完成纠错. 在生成多项式已知时, 计算机可以计算得到第一位出错时的余数. 
由于余数的循环性, 可以将循环码左移循环, 直到余数与目标余数匹配, 此时的首位便是出错位, 纠正后, 将循环码右移, 则可以得到正确数据.

新余数的计算有两种方式:
- 通过循环码直接除以多项式计算
- 通过余数补零计算
二者在数学上是等价的, 为了减小计算量, 工程中全部使用余数补零计算.

一个实际的案例如下:

信息位`0b1100`, 生成多项式`0b1011`. CRC 校验码`0b1100010`.
通过计算可以知道, 首位错误时, 即数据变为`0b0100010`时, 余数为`0b101`, 该余数为后续要匹配的余数.
若第 $7$ 位翻转, 校验码变为`0b1100011`, 纠错过程为:

$$
\begin{array}{|c|c|}
\hline
校验码 & \text{校验码 (mod 1011)} & 上次运算余数补零 & \text{补零余数 (mod 1011)}\\
\hline
110001{\color{red}1} & 001 & \text{N/A} & \text{N/A} \\
\hline
10001{\color{red}1}1 & 010 & 0010 & 010 \\
\hline
0001{\color{red}1}11 & 100 & 0100 & 100 \\
\hline
001{\color{red}1}110 & 011 & 1000 & 011 \\
\hline
01{\color{red}1}1100 & 110 & 0110 & 110 \\
\hline
1{\color{red}1}11000 & 111 & 1100 & 111 \\
\hline
{\color{red}1}110001 & 101 & 1110 & {\color{green}101} \\
\hline
\end{array}
$$

当余数为`0b101`时, 可以看到, 错误位正好位于首位, 将其翻转, 然后右移, 即可得到正确循环码.

通过计算也能发现, 通过循环码直接计算, 和通过余数补零计算的结果是等价的.

CRC 的除法, 准确地说是: 有限域 $\text{GF(2)}$ 上的多项式除法.
模运算是: 模 $\text{G(x)}$ 的多项式求余.

所有运算都发生在有限域 $\text{GF(2)}$ 上, $\text{GF}$ 代表 Galois Field , 即伽罗瓦域.
在该域中, 所有系数运算都需要模 $2$ .

CRC计算的核心步骤是找到一个余数多项式 $R(x)$ , 使得: 

$$
M(x)\cdot x^r = Q(x)\cdot G(x) + R(x)
$$

其中：
- $r$ 是 $G(x)$ 的阶数 (最高次幂).
- $M(x)\cdot x^r$ 相当于将原始数据 $M(x)$ 左移 $r$ 位 (在末尾添 $r$ 个 $0$ ).
- $Q(x)$ 是商多项式.
- $R(x)$ 是**余数多项式**, 即 CRC 校验码, 阶数小于 $r$ .


CRC 主要作为检错码使用, 仅需添加较少的冗余位 (通常是 8, 16, 32 位) , 即可对任意长度的数据块提供强大的错误检测能力, 尤其擅长检测突发错误.

汉明码主要作为纠错码使用, 对于 $k$ 位的数据, 需要添加 $\log_2(k+1)+1$ 个校验位, 随着 $k$ 增大, 所需要的校验位成**对数级**增长, 但对于非常大的数据块, 其编码效率不如 CRC 简洁.

对于突发错误, CRC 有很强的检错能力. 突发错误指的是集中出现的连续错误, 在实际通信中, 错误往往不是孤立的单个比特错误.
CRC 的生成多项式是经过数学精心挑选的, $r$ 位的 CRC 码可以保证检测到所有小于等于 $r$ 位的突发错误.

CRC 通常应用于快速可靠的判断接受到的数据是否与发送的数据完全一致. 例如文件校验, 网络通信.
Hamming Code 通常应用于不重传数据的情况下, 自动发现并修复少量错误. 例如内存的 ECC, 卫星通信, 光盘存储.

