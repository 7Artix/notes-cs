
# 计算机系统层次结构

计算机系统由 "**硬件**" 与 "**软件**" 两大部分组成. 计算机性能的好坏取决于软件与硬件功能的总和.
软件通常可以分为 "**系统软件**" 和 "**应用软件**".

直接执行机器语言的机器称为**实际机器** $M_1$ .

后续发展出**汇编语言**, 可以不直接编写二进制机器码, 将汇编语言翻译为机器语言的机器称为虚拟机, 此处的汇编语言机器可以记作 $M_2$ .

将**高级语言**翻译成汇编语言的虚拟机器可以记作 $M_3$ .

将高级语言程序翻译成机器语言程序的软件称为翻译程序, 翻译程序包含两种:
- 编译程序
- 解释程序

**编译程序**是将高级程序的全部语句一次全部翻译成机器语言程序. 因此只要源程序不变, 就无需再次进行翻译.

**解释程序**是将源程序的一条语句翻译成对应于机器语言的一条语句, 并立即执行该语句, 借着翻译源程序的下一条语句并执行, 如此重复直至完成源程序的全部翻译任务. 特点是翻译一次执行一次, 即使下次重复执行该语句也必须重新翻译.

在 $M_1$ 的内部也可以向下延伸形成下一级的**微程序机器** $M_0$ . $M_0$ 是直接将 $M_1$ 中的每一条机器指令翻译成一组**微指令**, 即构成一个微程序.  $M_0$ 是对实际机器 $M_1$ 的分解, 本质上 $M_0$ 也是实际机器.

为了区分 $M_0$ 和 $M_1$ , 通常将 $M_0$ 称为**传统机器** $M_1$ 称为**微程序机器**.

汇编语言机器和传统机器之间还有一级虚拟机器, 即**虚拟系统机器** 是由操作系统软件构成的.

硬件的研究为传统机器和微程序机器.
软件的研究主要是操作系统机器及以上的各级虚拟机.

计算机组成原理重点讨论传统机器和微程序机器的部分.

$$
\underset{(高级语言机器)}{虚拟机器M_4} \rightarrow 
\underset{(汇编语言机器)}{虚拟机器M_3} \rightarrow 
\underset{(操作系统机器)}{虚拟机器M_2} \rightarrow 
\underset{(机器语言机器)}{传统机器M_1} \rightarrow 
\underset{(微指令系统)}{微程序机器M_0}
$$


# 计算机组成和计算机结构

区分计算机组成和计算机结构

**计算机结构**侧重于机器是否具有某种功能
**计算机组成**侧重于机器如何实现某种功能

例如, 一台机器是否具备乘法指令功能是结构问题; 如何实现乘法指令是组成问题, 可以采用专门的乘法电路, 也可以用累加实现.

计算机组成原理主要研究计算机的组成, 有关计算机结构在计算机体系结构中讨论.


# 计算机基本组成

## 冯诺依曼机
- 计算机由**运算器**, **存储器,** **控制器**, **输入设备**和**输出设备**5大部件组成
- 指令和数据以同等地位存于存储器内, 并可按址寻访.
- 指令和数据均用二进制数表示.
- 指令由操作码和地址码组成. 操作码用来表示操作的性质, 地址码用来表示操作数在存储器中的位置.
- 指令在存储器内按顺序存放. 通常情况下是顺序执行的, 特定条件下可根据运算结果或设定的条件改变执行顺序.
- 机器以运算器为中心, 输入输出设备与存储器之间的数据传送通过运算器完成.

典型的冯诺依曼机以运算器为中心, 现代计算机已转变为一存储器为中心.

5大子系统功能如下:
- **运算器(Arithmetic Logic Unit, ALU)** 负责完成算数运算和逻辑运算, 并将运算的中间结果暂存在运算器内
- **存储器(Memory Unit)** 负责存放数据和程序.
- **控制器(Control Unit)** 负责控制, 指挥程序和数据的输入, 运行, 以及处理运算结果.
- **输入设备**负责将人类的输入转换为机器能够识别的信息形式.
- **输出设备**负责将机器的运算结果转换为人类能够理解的信息形式.

子系统在控制器的指挥下进行自动工作.

运算器和控制器在逻辑关系和电路结构上联系紧密, 在现代集成电路中,通常集成在 **CPU(Central Processing Unit)** 上. 输入输出统称为I/O设备.

现代计算机可以认为由三大部分组成: CPU, I/O设备, 以及主存储器.

CPU和主存储器合起来称为主机, I/O设备称为外部设备.

存储器通常指的是主存储器, 即内存, 而不是外存.


## 计算机工作步骤

计算机解决问题通常包含两大步骤, 一个是上机前的准备, 另一个是上机运行.

上机前准备包括:
1. 建立数学模型
2. 确定计算方法
3. 编写解题程序

计算机的运行过程如下.


### 主存储器

主存储器包含存储体 $M$ , 各种逻辑部件以及控制电路. 
**MDR**存储数据寄存器
**MAR**存储地址寄存器

存储体由许多**存储单元**组成, 每个存储单元包含若干**存储元**, 每个存储元存储1bit. 每个存储单元包含的存储元数量称为**存储字长**.

主存的工作方式为按照存储单元的地址号, 来实现对存储字各位的存取(写入读出). 这种存取方式称为**按地址存取(访存)**. 
访存可以让程序通过计数器加一的形式自动形成下一条指令的地址, 从而自动完成操作. 而当反复使用某条指令或数据的时候, 只要指定相应的地址号即可, 而不需要用存储单元反复存储某一数据或指令.

为了实现按地址访问, 主存储器配置了MAR和MDR. 
MAR用来存放将要访问的存储单元的地址. 其位数对应存储单元的数量.
MDR用来存放从存储单元取出的代码, 或即将存往存储单元的代码. 其位数与存储字长相等.

早期计算机存储字长和机器指令字长与数据字长相等. 因此访存一次, 即可获取一条指令或数据. 
随着技术发展, 指令字长和数据字长要求可变. 为了实现可变指令和数据字长, 其长度不由存储字长决定, 而是由字节个数表示. 如4字节数据为32bit二进制码, 2字节指令为16bit二进制码. 
此时数据字长, 指令字长与存储字长可以互不相同, 但是必须都是字节的整数倍.

主存内的数据需要通过MAR或MDR与控制器, 运算器或输入输出设备交互.


### 运算器

运算器最少包含3个寄存器 (现代通常由通用寄存器组), 和一个算术逻辑单元(ALU)
三个寄存器分别为:
- 累加器ACC (Accumulator)
- 乘商寄存器MQ (Multiplier-Quotient Register)
- 操作数寄存器X

不同计算机有不同的运算器结构.


### 控制器

控制器是计算机的神经中枢, 负责指挥各个组件自动, 协调地工作.
(取指阶段) 控制器首先命令存储器读出一条指令, 称为取指.
(分析阶段) 针对取指的指令进行分析, 确认指令要完成什么操作, 并按寻址特征指明操作数地址.
(执行阶段) 根据操作数所在的地址以及指令的操作码完成具体操作.

控制器由**程序计数器 (Program Counter, PC)**, **指令寄存器 (Instruction Register, IR)**, 以及**控制单元 (CU)** 组成.

PC用来存放当前欲执行指令的地址, 与主存MAR之间有直接通路, 具备自动+1功能, 可自动形成下一条指令的地址.
IR用来存放当前指令, IR内容来自MDR. 
IR中的操作码 (OP(IR)) 送至CU, 记作OP(IR)→CU, 用来分析指令.
IR中的其他地址码 (Ad(IR)) 作为操作数地址送至MAR, 记作Ad(IR)→MAR.
CU用来分析当前指令所需完成的操作, 发送各种微操作命令序列, 用来控制所有被控对象.


### I/O

I/O子系统包含I/O设备以及对应的接口.


---

一个简单的过程如下:

$$
\begin{array}{ll}
PC \rightarrow MAR & 指令地址发送到主存, 并命令主存做读操作 \\
M地址内容 \rightarrow MDR & 程序指令被读入到MDR内部\\
MDR \rightarrow IR & 完成一次取指令 \\
OP(IR) \rightarrow CU & CU解析指令 \\
Ad(IR) \rightarrow MAR & CU将预操作的地址送至MAR \\
CU操作 & CU根据指令执行对应操作, 如取数\\
\end{array}
$$


# 计算机硬件指标

## 机器字长

指CPU单次处理数据的位数, 通常与CPU的寄存器位数相关.


## 存储容量

包含主存与辅存的容量


## 运算速度

用Gibson法从何考虑每条指令的执行时间, 以及在全部操作中的占比, 来衡量运算速度.

$$
T_M=\sum_{i=1}^{n}f_it_i
$$

$T_M$ 为运行速度, $f_i$ 为第 $i$ 种指令占全部指令的比例, $t_i$ 为第 $i$ 种指令的执行时间.

现代使用单位时间内执行指令的平均条数来衡量性能, 使用MIPS (Million Instruction Per Second) 作为单位.
也可以使用CPI (Cycle Per Instruction) 即执行一条指令所需的时钟周期 (机器主频的倒数) 或用FLOPS (Floating Point Operation Per Second) 即每秒浮点运算次数, 来衡量运算速度.

$$
CPU执行时间 = 指令条数 \times CPI \times 时钟周期时间
$$

CPI越小, 性能越高. 更多用于评估内部设计和指令集架构效率, 是偏向理论和架构层面的指标.
从处理器设计角度, 通过优化流水线, 增加执行单元, 改进缓存系统提升.
从编译器优化角度, 研究指令重排, 循环展开等技术.
CPI可以帮助分析性能瓶颈.
CPI不能直接代表CPU性能, 需要结合时钟频率和指令条数才能全面评估性能.
现代CPU可以在一个时钟周期内执行多个指令, 因此常使用IPC来衡量性能.
IPC越大, 性能越高.

主流桌面CPU的IPC通常在1.5~3. Apple Silicon可以达到4~6. 嵌入式芯片在1~2

不同的指令的执行效率
简单整数运算指令可以在单个时钟周期内完成, 例如加减, 逻辑与或, 位移等.
复杂整数运算指令需要几个至十几个周期, 例如整数乘法, 整数除法.
浮点运算指令加减法和乘法可能需要几个至十几个周期, 触发可能需要几十个周期.
内存访问指令波动较大, 从几个周期到几百个周期不等. 取决于命中率
分支跳转指令通常需要几个周期, 如果分支预测失败则可能导致几十至上百个周期.

