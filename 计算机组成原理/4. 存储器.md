
# 概述

## 存储器分类

按存储介质分类, 存储器可分为:
- 半导体存储器
- 磁表面存储器, 如: 磁盘, 磁带, 磁鼓
- 磁芯存储器, 用磁环存储数据, 磁环中穿过驱动线和读出线
- 光盘存储器

按存取方式, 存储器可分为:
- <font color=red><b>RAM</b></font> Random Access Memory, 随机存储器. 其中任何一个存储单元的内容都可以随机存取, 存取时间与存储单元的物理位置无关. RAM又分为SRAM(静态)和DRAM(动态). SRAM利用触发器寄存, DRAM利用电容寄存.
- <font color=red><b>ROM</b></font> Read Only Memory, 派生出PROM, EPROM, EEPROM. 后续发展出Flash Memory

另外还有串行访问存储器, 在读写操作室, 需要按照物理位置先后顺序进行寻址. 例如: 磁带. 磁盘也属于部分串行访问的存储器.


按在计算机中的作用分类, 可分为:
- <font color=red><b>主存</b></font>: 可以直接与CPU交换信息.
- <font color=red><b>辅存</b></font>: 不直接与CPU交换信息, 用于存放暂时不用的程序和数据.
- <font color=red><b>缓存</b></font>: 用在两个速度不同的部件之间起缓冲, 例如CPU和主存之间.

时至今日, 存储器的分类与作用为:

主存: DRAM
辅存: Flash Memory, 磁盘
缓存: SRAM

存储器的层次结构为:

$$
\begin{array}{c}
寄存器 \\
\Downarrow \\
缓存 \\
\Downarrow \\
主存 \\
\Downarrow \\
辅存
\end{array}
$$

越下层的存储器速度越慢, 容量更大, 成本更高.

理论上CPU可以直接和主存进行数据交换, 但是几乎从不这么做. 
现代计算机的CPU都是通过多级Cache获取数据, 而不会直接访问主存, 这是由于访问主存速度很慢, 可能会影响上百个CPU时钟周期.

主存和缓存之间的数据调动是硬件自动完成的, 对程序员透明.

<font color=red><b>MMU</b></font>通常在CPU与主存之间, 其核心职能为**虚拟内存管理**. 负责转换虚拟地址空间和物理地址空间: 
1. 地址翻译: 根据页表将虚拟地址翻译成物理地址. 使每个进程都认为自己独占一整片内存空间, 但实际可以映射到不同物理页.
2. 权限检查
3. 页异常管理

虚拟内存是围绕**页**展开动作的. 页是虚拟地址空间与物理地址空间映射的最小块. 
页表记录了虚拟页和物理页的映射关系.
常见页大小为4KB.

程序始终访问虚拟地址, 真实物理地址对程序透明. 每一次程序对数据的访问, MMU都会介入地址翻译.
现代CPU会在MMU内放一个小Cache (Translation Lookaside Buffer, TLB), 若命中, 则可以直接跳过页表查询.
对于CPU的一次数据访问, MMU会:
1. 查询 TLB, 若命中则直接得到物理地址.
2. Cache查找
3. DRAM查找
4. Flash查找


# 主存

主存的MDR通常设计为与CPU机器字长相等宽度. MAR通常设计为和地址总线宽度相等.

MDR和MAR都在CPU内部, 现代CPU通过Address Generation Unit和Load/Store Buffer取代了MDR和MAR.

现代主存使用<font color=red><b>DDR SDRAM</b></font>. 抽象的MAR和MDR之后, 输入到内存控制器中, 由内存控制器, 通过DDR PHY连接到内存.

内存上有被动逻辑执行单元, 用来译码地址, 解析命令, 对存储单元进行操作.

SRAM是使用触发器电路的存储结构.

DRAM是使用电容的存储结构. 由于电容中的电荷会消失, 因此DRAM需要进行刷新, 来保证数据的存储. 刷新周期通常为几ms至几百ms.
DRAM有三种刷新方式:
- 集中刷新: 在规定的一个刷新周期内, 对全部存储单元集中一段时间进行逐行刷新. 刷新过程中需要停止读/写操作. 不能进行读/写的时间称为访存死区, 所占比率称为死时间率.
- 分散刷新: 将每一个存取周期均划分成读写阶段和刷新阶段, 在刷新阶段对存储芯片进行刷新. 没有死区, 但是会延长存取周期, 造成浪费.
- 异步刷新: 按行数将刷新动作平分到整个刷新周期, 对于每一段来说是集中刷新, 对于整体来说是分散刷新. 将刷新安排在CPU指令译码阶段, 避免死区问题.

TTL和CMOS的主要区别:
TTL的核心器件是BJT, 是电流控制型器件, 需要电阻限制电流, 功耗较大.
CMOS的核心器件是MOSFET, 是电压控制型器件, 几乎不需要电流, 功耗极低.

PROM在每位存储单元内有熔丝, 熔丝断与未断用于存储数据.

EPROM和EEPROM是通过浮动栅型MOSFET, 利用浮动栅实现0和1的存储. 浮动栅被绝缘层隔绝, 存储的电荷不能轻易移动, 不会轻易消失.

Flash 也使用浮动栅型 MOSFET 存储数据. Flash 的擦除是通过块擦除的模式.
NOR Flash 每个存储单元有独立的位线, 可以随机访问单个字节. NAND Flash 按块读写.
Flash 通过精确控制浮动栅中电荷量的不同, 区分出多个电压阈值区间, 从而在一个单元中存储多位信息, 即: SLC, MLC, TLC, QLC.


## 存储器与CPU的连接

由于单片存储芯片容量有限, 因此通常需要将若干存储芯片组合, 称为存储容量的扩展, 分为位扩展与字扩展.
- 位扩展: 增加存储字长, 例如 2片 1K×4 bit 的芯片构成 1K×8 bit 的存储器.
- 字扩展: 增加存储器字数量, 例如 2片 1K×8 bit 的芯片构成 2K×8 bit 的存储器.
- 字, 位扩展: 组合以上两种方式.

存储器与CPU连接包括地址线, 数据线, 控制线(读/写命令线, 片选线)

## 汉明码

汉明码是一种检错纠错的编码, 具有1位纠错能力.

<font color=red><b>汉明距离</b></font>是两个等长传对应位置不同字符的数量.
<font color=red><b>最小码距</b></font>是编码中任意两个有效码字之间的最小汉明距离.
有如下公式:

$$
d-1 = e+c
\quad (e\geq c)
$$

其中 $d$ 是最小码距, $e$ 是检错位数, $c$ 是纠错位数. 
增加冗余码可以提高最小码距, 提升纠错能力, 会降低码率. 
将上述公式变换:

$$
\begin{array}{l}
要检测\ e\ 个错误: d \geq e + 1 \\
要纠正\ c\ 个错误: d \geq 2c + 1
\end{array}
$$

汉明码通常表示为 $(n,k)$ 码, 其中:
- $k$ : 信息位的位数, 即原始数据长度
- $r$ : 校验位的位数
- $n$ : 总长度, $n = k + r$ 

对于纠正 1 bit 错误, 需要的校验位数 $r$ 必须满足 $2^r \geq k+r+1$ 或 $2^r \geq n + 1$ .

汉明码被设计为能够判断数据中的哪一位出现错误. 对于总长为n的码字, 错误可能发生在n个位置中的任意一个, 也可能不发生错误, 即一共 $n+1$ 种状态. 

汉明码的核心思想是用 $r$ 个校验位, 生成一个 $r$ 位的二进制数, 这个数即错误地址.

由此可见, 对于能够表示错误发生位的前提是, $2^r$ 一定大于等于总码字长 $n+1$ .

例如: 校验位数 $r = 3$ , 则:
- $0b000 = 0$ 表示无错误.
- $0b001 = 1$ 表示第 1 位出错.
- $\cdots$
- $0b111 = 7$ 表示第 7 位出错.

可见, 当 $r=3$ 时, 最多可以处理7位数据的纠错需求.

7 位数据中, 去除校验位的 3 位, 剩余的 4 位是原本的实际数据位.

在以上基础前提要求下, 汉明码通过精心安排校验位的检测范围, 巧妙地做到了伴随式 $S$ 的值与错误发生的位序号完全一致.

编码规则为:
- 将 $r$ 个校验位 $P_1, P_2, \cdots, P_r$ 放在位序号 $1,2,4,\cdots,2^{r-1}$ 上 (从 $1$ 开始记) . 
- 将每个校验位 $P_i$ 定义为对所有位序号中包含 $2^{i-1}$ 的位进行校验 (通常是奇偶校验) .

以 $(7,4)$ 码为例:

$$
\begin{array}{c|c|c}
\hline
位序号 & 二进制分解 & 对应校验位 \\
\hline
1 & 001 = 4^0 + 2^0 + 1^{\color{red}1} & 受P_{\color{red}1}检验 \\
\hline
2 & 010 = 4^0 + 2^{\color{red}1} + 1^0 & 受P_{\color{red}2}检验 \\
\hline
3 & 011 = 4^0 + 2^{\color{red}1} + 1^{\color{red}1} & 受P_{\color{red}1}, \ P_{\color{red}2}检验 \\
\hline
4 & 100 = 4^{\color{red}1} + 2^0 + 1^0 & 受P_{\color{red}3}检验 \\
\hline
5 & 101 = 4^{\color{red}1} + 2^0 + 1^{\color{red}1} & 受P_{\color{red}1}, \ P_{\color{red}3}检验 \\
\hline
6 & 110 = 4^{\color{red}1} + 2^{\color{red}1} + 1^0 & 受P_{\color{red}2}, \ P_{\color{red}3}检验 \\
\hline
7 & 111 = 4^{\color{red}1} + 2^{\color{red}1} + 1^{\color{red}1} & 受P_{\color{red}1}, \ P_{\color{red}2}, \ P_{\color{red}3}检验 \\
\hline
\end{array}
$$

假设第 $6$ 位出错, 对应二进制编码为 $110$ , 该位受 $P_2$ 和 $P_3$ 检验. 
则 $P_2$ 和 $P_3$ 检验到错误后变为 $1$ , $P_1$ 由于没有被影响, 因此保持 $0$ . 
此时伴随式 $S$ 的值为 $6$ , 与出错位序号相同, 据此进行纠错即可.

从上表可知:
- $P_1$ 覆盖第 $1,3,5,7$ 位.
- $P_2$ 覆盖第 $2,3,6,7$ 位.
- $P_3$ 覆盖第 $4,5,6,7$ 位.

将校验码与数据整合, 其结构为:

$$
\begin{array}{}
位序号 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\
内容 & D_4 & D_3 & D_2 & P_3 & D_1 & P_2 & P_1 \\
\end{array}
$$

校验位的任务是让其覆盖的所有位满足特定的奇偶性.

对于偶校验而言, 使用异或运算得到的校验位能够使一组位中, $1$ 的总个数为偶数, 即:

$$
偶校验位 = 覆盖信息位的异或和
$$

对于奇校验而言, 使校验位在偶校验的基础上取反, 即:

$$
奇校验位 = \overline{偶校验位} = \overline{覆盖信息位的异或和}
$$

由于偶校验更简单, 因此实际偶校验使用更广泛.

下面以偶校验 $(7,4)$ 码举一个实际案例.

$$
\begin{array}{}
位序号 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\
内容 & D_4 & D_3 & D_2 & P_3 & D_1 & P_2 & P_1 \\
数据 & 1 & 1 & 0 & - & 1 & - & - \\
\end{array}
$$

即待发送数据为 $1011$ . 分别计算各个校验位的值:

$$
\begin{array}{}
P_1 = 3_{位} \oplus 5_{位} \oplus 7_{位} = D_1 \oplus D_2 \oplus D_4 = 0 \\
P_2 = 3_{位} \oplus 6_{位} \oplus 7_{位} = D_1 \oplus D_3 \oplus D_4 = 1 \\
P_3 = 5_{位} \oplus 6_{位} \oplus 7_{位} = D_2 \oplus D_3 \oplus D_4 = 0
\end{array}
$$

最终计算得到汉明码为:

$$
\begin{array}{}
位序号 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\
内容 & D_4 & D_3 & D_2 & P_3 & D_1 & P_2 & P_1 \\
数据 & 1 & 1 & 0 & {\color{green}0} & 1 & {\color{green}1} & {\color{green}0} \\
\end{array}
$$

假设传输中第 $5$ 位发生翻转, 数据变为 $1110110$ , 重新计算伴随式 $S=C_3 C_2 C_1$ .

翻转后的数据为:

$$
\begin{array}{}
位序号 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\
数据 & 1 & 1 & {\color{red}1} & 0 & 1 & 1 & 0 \\
\end{array}
$$

$$
\begin{array}{}
C_1 = 1_{位} \oplus 3_{位} \oplus 5_{位} \oplus 7_{位} = 0 \oplus 1 \oplus 1 \oplus 1 = 1 \\
C_2 = 2_{位} \oplus 3_{位} \oplus 6_{位} \oplus 7_{位} = 1 \oplus 1 \oplus 1 \oplus 1 = 0 \\
C_3 = 4_{位} \oplus 5_{位} \oplus 6_{位} \oplus 7_{位} = 0 \oplus 1 \oplus 1 \oplus 1 = 1
\end{array}
$$

得到伴随式 $S=101b=5$ , 因此第 $5$ 位被翻转. 修正后可以得到正确的元数据.


汉明码仅能够进行1位纠错. 拓展汉明码可以进行多位检错, 例如 $(8,4)$ 码可以检测 2 位错误, 并且纠正 1 位错误.

两位即以上纠错码, 类似BCH码, 需要更复杂的编码解码机制, 其对应码距也更大.


## 提高访存速度

### 单体多字系统

对于连续存储在主存内的指令, 可以通过**单体多字**系统, 使用 1 个地址, 在一个存取周期内同步取出多个指令. 
例如, 单体四字结构中, 一次访存动作, 取回4个连续的指令.
为了实现单体多字, 数据总线宽度必须加宽, 例如原本是 64-bit 的标准单字, 为了实现单体四字, 数据总线必须扩宽到 256-bit .

现代设备框架中, 地址总线, 数据总线和控制总线的概念被模糊. 通常使用专用接口连接CPU和内存.
CPU内部通常继承了内存控制器 (原本在北桥芯片中), 通过DDR通道与内存相连.

Burst Mode, 即**突发模式**是体系中一种为了提升效率的带宽优化技术. 
Burst Mode 利用了两个传输过程的特点:
- 高延迟: DRAM内存访问的延迟 (从发出请求, 到第一个数据可用) 很高. 这是由于需要进行行地址选通 (RAS) 和列地址选通 (CAS) 等操作.
- 高带宽: 一旦DRAM内部操作完成, 内存可以以非常高的速度持续读出数据.

单体多字利用了高延迟和高带宽的特点, 付出 1 次高延迟的代价, 获得多分数据, 提高了带宽.

Burst Mode 的具体实现是通过控制总线上的不同命令实现的.

以下为 CPU 和 Cache 各自可以完成的工作:
- CPU 发起**单字存取**: 若数据 Hit 在 Cache 中, 则直接取走, 若 Miss , 则触发Cache的块传输流程, 发起 Burst Mode 从内存中取数据.
- Cache 发起**块传输**: 发起 Burst Mode 进行 Cache 行填充.


### 多体并行系统

多体并行系统是将主存分割成多个独立的, 可以并行工作的存储体. 存储体是交错组织的, 连续的地址会被分配到不同的存储体中. 

例如, 在 CPU 请求连续的 4 个数据时, 内存控制器可以同时向 4 个存储体 (假设有 4 个存储体) 发送请求, 虽然单独存储体延时不变, 但由于操作时并行的, 因此 CPU 依然可以在一个周期内接受来自不同体的 4 个数据, 从而使带宽增加. 

在内存颗粒内部, 多体并行体现为 Bank 级并行. 
内存控制器可以向同一颗粒中的不同 Bank 发送请求, 这允许在等待 1 个 Bank 完成其较长的行激活 (RAS) 操作时, 同步可以对另一个 Bank 进行列访问 (CAS) 操作, 提高单个芯片的利用率和吞吐.

另外, 双通道 DDR 也是多体并行系统的应用. 通过双通道, 可以使数据带宽翻倍.


## DDR

Double Date Rate SDRAM , 即**双倍数据率同步动态随机存储器**. 其数据传输速率为系统主频的 2 倍. DDR 在系统时钟的上升沿和下降沿都可以进行数据传输.

DDR 规定了一系列的标准, 包括:
- 存储介质类型: 规定了存储单元的基本电气特性和读写时序
- 接口 / 总线协议: 规定了内存颗粒与内存控制器之间通信的物理和逻辑协议, 包括数据, 地址, 控制线的数量, 电压, 以及时序. 定义了 CPU 内存控制器与内存模组的通信规则.
- PHY: 规定了物理层, 包括引脚设计, 阻抗匹配, 信号完整性要求, 电压, 传输方式等.
- 通信规范: 详细的时序参数, 传输机制等.

有一些参数可以影响 DDR 内存的传输速率.

- **数据传输速率**. 例如 DDR5-5600 , 表明数据传输速率为 5600MT/s . 
  根据 DDR 的双倍原理, 内存系统总线的实际时钟频率 ( DDR Clock 或 Base Clock ) 是传输速率的 $1/2$  , 即 2800 MHz . 该频率代表内存模块支持的最高速度. 实际运行速度受 CPU 内存控制器, 主板, BIOS影响. 
  内存时钟由 CPU 内部的 MC 驱动和控制, 实际由主板产生.
  内存速度并没有匹配上 CPU 的速度, 因此存在 Cache .

- **内存时序**. 内存时序通过一系列参数表示: CL-tRCD-tRP-tRAS.
	- <font color=red><b>CL</b></font> (CAS Latency, Column Address Strobe Latency), 即 CAS 延迟. 指从内存控制器发出读取数据命令 (CAS信号) 到数据开始从 DRAM 的 I/O 引脚传出, 所需要的最小等待周期数. CL 是最常见的参数, CL 越小, 内存响应越快.
	- <font color=red><b>tRCD</b></font> (Time Row to Column Delay), 即 RAS 到 CAS 延迟. 指从激活一行 (发出 RAS 信号) 到发出列读取命令 (CAS 信号) 所需的最小等待周期数. 这是因为, 一行被激活后, 需要时间将数据从存储单元传输到感应放大器中稳定, tRCD就是保证稳定性的延迟.
	- <font color=red><b>tRP</b></font> (Time Row Precharge), 即行预充电时间. 指从关闭 (预充电) 当前行到激活新行所需要的最小等待周期数. DRAM 访问完 1 行后, 必须对该行进行预充电 (恢复平衡状态) , 才能激活下一行. 预充电本质就是数据恢复 (重写) , 恢复被读操作破坏的数据. 另外需要将位线恢复到参考电压, 以备让放大器检测新行的电荷.
	- <font color=red><b>tRAS</b></font> (Time Row Active Strobe), 即行激活时间. 一行被激活 (发出 RAS 信号) 到它必须被关闭 (预充电) 之间的最短时间. 这是为了防止数据丢失, 确保 DRAM 内部操作能够完成的最小时间, 若 tRAS 太短, DRAM 可能无法完成内部操作.

一个完整的行数据访问, 然后切换到新行的操作顺序如下:
1. 激活: MC 发出 RAS 信号, 要求进行行访问, tRAS开始计时.
2. 读写: MC 发出 CAS 信号, 属于 tRAS 内部过程, 进行数据读写.
3. 关闭 (预充电): 当满足 tRAS 后, MC 发出预充电命令, tRP 开始计时, tRAS结束.
4. 新激活: tRP 满足后, MC 发出下一个 RAS 信号, 激活新行, 开启下一个循环.

当触发 Burst Mode 且数据在同一行时, 进行一次 RAS 后, 可以进行多次 CAS , 完成后再进行 Precharge.

DRAM 的刷新内存指令也是由 MC 发出的.

MC 会将 MMU 给出的物理地址进行逻辑划分, 分为 3 个部分: Bank 地址, 行地址, 列地址.
随后, MC 会分时发送地址:
- 发送 Bank 地址和行地址, 发出 RAS 信号.
- 发送列地址, 发出 CAS 信号.

MC 会通过读取内存的 SPD (Serial Presence Detect) 信息 (通过低速总线, 如 $I^2C$ ) , 获取内存的详细信息, 包括总容量, 颗粒配置 (Bank 数), 时序参数等.

在开机识别信息后, MC 会计算总 Bank 数, 会根据最佳性能原则, 如交错寻址, 将物理地址划分并映射到整个物理内存可用的 Bank 或 DIMM (Dual Inline Memory Module, 双列直插内存模块, 即两面金手指不互通, 有双倍通道) 上.

DRAM内部会负责译码与定位, 会将对应地址输出为具体信号线, 激活对应的行列.

双通道内存是一种多体并行系统的应用.

对于多通道内存, 现代架构是通过星型拓扑, 即独立内存通道进行连接的. 
每个通道都拥有独立的数据, 地址, 控制信号. 对于双通道而言, MC 可以同时激活通道 A 和通道 B , 实现并行访问.
此外, CPU 可能支持双通道, 但主板上有 4 槽位, 此时 1, 3 可能属于通道 A, 而 2, 4 可能属于通道 B .


## 内存相关的控制设备

<font color=red><b>MMU</b></font> (Memory Management Unit, 内存管理段元)

MMU 在 CPU 内部. 
核心职责为虚拟地址和物理地址的转换.
关键机制依赖于页表 (Page Table) 和快表 (Translation Lookaside Buffer, TLB)


<font color=red><b>MC</b></font> (Memory Controller, 内存控制器)

现代 MC 大多在 CPU 内部, 早期位于北桥.
核心职责为协议翻译和时序控制, 是 CPU 侧的总线接口.
MC 接受 CPU 的读写请求, 以及 MMU 提供的物理地址, 将这些请求翻译成 DDR 协议下规定的电信号和时序. MC还管理数据总线和地址总线, 确保数据能够以 Burst 模式高效传输.


**内存颗粒**

内存颗粒内部也有对应的逻辑电路, 包括地址解码器, 读写缓冲器, 时序和逻辑控制器等.
内存颗粒按照 DDR 协议的要求, 完成数据的存取, 刷新等操作.


**Cache Controller**

Cache Controller 是所有数据和指令存取的第一站, 决定了是否需要访问内存.
负责检查 CPU 要求的地址是否命中, 若 Cache Miss 则会发起一个块传输请求给 MMU 和 MC , 要求从主存中拉取一整个 Cache Line.


# Cache

通常 I/O 对主存请求的优先级高于 CPU , 会出现 CPU 等待 I/O 访存的问题, 降低 CPU 工作效率.
此外, 主存速度始终跟不上 CPU 的速度, 也造成主存与 CPU 速度不匹配. 
因此, 需要 Cache 缓解二者之间的速度差异.

Cache 的可行性, 是由于 CPU 在一定时间内从主存存取指令或存取数据时, 通常都是对主存的局部区域进行访问. 这是由于数据和指令在主存内通常都是连续存储的. 
此外, 部分数据和指令会被多次调用, 如子程序, 循环程序, 函数等.
由于指令和数据在主存中的地址分布不是随机的, 即**程序访问的局部性原理**, 引入采用 SRAM 的 Cache 可以缓解主存和 CPU 之间的速度差异.

Cache 的工作原理

主存由 $2^n$ 个可编址的字组成, 每个字有唯一的 $n$ 位地址. 
为了与 Cache 映射, 将主存与 Cache 都分成若干<font color=red><b>块</b></font>, 每个块内包含若干个字, 使块大小相同, 即块内的字数相同. 
将主存的地址分成两段, 高 $m$ 位表示**块地址**, 低 $b$ 位表示**块内地址**, $2^m$ 表示主存的块数.
Cache 地址同样分成两段, 高 $c$ 位表示缓存**块地址**, 低 $b$ 位表示**块内地址**, $2^c$ 表示 Cache 的块数.
$2^c << 2^m$ . $2^b$ 反映了块的大小, 称为块长.

任意时刻, 均有一些主存块处于 Cache 块中.

CPU 请求某主存字时, 存在两种可能:
- Hit, 字已在 Cache 中, 直接访问.
- Miss, 字不在 Cache 中, 将该字所在字块一次调入 Cache 中.

Cache 中的每一个块设有一个标记, 用于记录当前存放的是哪一个主存块, 对应主存的高 $m$ 位块地址.

Cache 的块数与块长是影响效率的重要因素. 用命中率来衡量 Cache 的效率, 命中率是指 CPU 访问的信息已在 Cache 中的比率. 

$$
命中率\ h = \frac{N_c}{N_c + N_m}
$$

- $N_c$ 命中次数.
- $N_m$ 未命中次数.

$$
Cache-主存系统平均访问时间\ t_a = 
ht_c + (1-h)t_m
$$

- $t_c$ Cache 访问时间.
- $t_m$ 主存访问时间.

通常, Cache 容量越大, 命中率越高, 但当 Cache 达到一定大小后, 命中率不会有进一步的明显提升. 
块长与命中率之间的关系更为复杂. 随着块长增加, 由于局部性原理, 临近的字可能也会被访问, 因此块长增加可将更多有效字存入缓存, 提升命中率. 但若持续增加, 则可能被过长的块替换掉有用的数据, 造成命中率降低.

Cache 的基本结构包括:
- 存储体: 用于与主存交换数据, 访存优先级最高.
- 地址映射变换机构: 用于将 CPU 提供的主存地址, 转换为 Cache 地址, 即块号映射.
- 替换机构: 当 Cache 已满, 替换机构按一定的替换算法确定从 Cache 中将某些块移回主存, 将新块移入 Cache .

在写数据时, 需要保持 Cache 和主存的数据一致, 有如下几种方法:
- 写直达法 (Write-through), 也称存直达法 (Store-through), 即写操作时, 数据同时写入 Cache 和主存, 保证了数据始终一致, 但增加了访存次数.
- 写回法 (Write-back), 也称为拷回法 (Copy-back), 即写操作时, 数据仅写入 Cache, 当 Cache 块即将被替换时, 才将数据写回主存. 
  写回法中, 块有两种状态: Clean 和 Dirty. 每一个块都需要增加一个标记位, 用来记录状态. Cache 替换时, Clean 的块不需要写回主存, Dirty 的块需要写回主存.

目前的 CPU 大多采用多级缓存的方案.

另外, Cache 还分为统一缓存和分立缓存.
- Unified Cache 将指令和数据存储在同一块缓存中. L2 和 L3 通常采用统一缓存.
- Split Cache 将指令和数据分成不同的缓存. L1 通常采用分立缓存.

使用分立缓存可以并行地在 1 个时钟周期内, 同时获取指令和数据, 防止竞争端口.
分立缓存也可以更好的支持流水线操作.


<font color=red><b>流水线执行</b></font> (Pipelining) 

流水线执行是现代 CPU 提升 IPC 的核心技术.
早期 CPU设计中, 一条指令必须完全执行完毕后, 下一条才能开始执行, 称为**串行执行**.
流水线执行通过将指令的执行过程分解为一系列独立的串行连接的阶段 (Stage), 允许阶段并行工作.

例如经典的 RISC (ARM就是 Advanced RISC Machine) 设计中, 指令执行分解成 5 个主要阶段: