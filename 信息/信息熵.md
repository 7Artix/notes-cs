
在 USB 4 协议中, 信号使用了 <font color=red><b>PAM-3</b></font> 电平进行传输. 相较于传统的传输中仅有 `0` 和 `1` , PAM-3 电平有 `0`, `1` 和 `2` .

PAM-3 相较于传统的 TTL 电平的信息传输量提升了多少呢? 
结果并不是简单的 $\dfrac{3}{2}=1.5$ , 而是 $\log_{2}{3}\approx 1.585$ 倍.

计算信息量的变化, 要考虑每个符号能携带多少 bit 的信息, bit 在此处是衡量信息量的基准单位. 

<font color=red><b>信息熵</b></font> $H$ 是衡量一个离散随机变量所含不确定性或信息量的数学期望.
对于一个有 $M$ 种可能状态 (符号) 的信息源, 即信源 $X$ , 其信息熵的定义为:

$$
H(X) = -\sum_{i=1}^{M}
P(x_i)\cdot\log_{2}(P(x_i))
$$

其中, $P(x_i)$ 是第 $i$ 个状态 (符号) 出现的概率.

信息熵在所有状态出现的概率相等时达到最大值 $H_{\max}$ .
在等概率情况下, 信息熵可以直接用 $\log_{2}(M)$ 计算.

信息量是关于消除不确定性的度量, 而这个度量与状态的数量呈对数关系, 而非线性关系.

熵越大, 表明信源的不确定性 (杂乱性) 越高, 因此每个符号平均所携带的信息量越大.
即, 越混乱, 含有的信息越多.
为了使信息熵最大化, 即每个符号携带的信息最多, 期望所有可能状态出现的概率是相等的.

可以通过汉字来理解. 
汉字的数量越多时, 即可能得状态越多时, 组合起来能表达的含义更多. 
但某些生僻词和一些高频字能使用的场合并不相同. 
生僻字和高频字的出现, 导致了实际信息熵远小于最大信息熵, 也正是因为概率不均衡, 使得数据压缩, 例如输入联想, 文本编码优化成为可能. 这是因为存在<font color=red><b>信息冗余</b></font>.

<font color=red><b>bit</b></font> 是最高效的存储方式, 本质上, 通过 bit 的存储代表了一种二元决策. 
<font color=red><b>bit</b></font> 是信息的基本单位, 代表最小, 最基本, 最高效的决策单元.

任何信息, 状态, 或符号, 无论其形式如何, 其信息量的多少都可以用 "**能够等效于多少个独立且概率相等的二元决策**" 来衡量, 即化为 bit 单位.

因此, 在相同的时钟频率下, PAM-3 相较于二进制电平的信息量并不是 $\dfrac{3}{2}$ 的关系, 而是 $\log_{2}3$ 的关系. 
这是由于符号本身就不是衡量信息量的标准, 信息量是用 bit 衡量的.

<font color=red><b>信息量</b></font>定义为: 消除不确定性所需的二元决策 "是/否" 的次数.
因此, 其相对于符号的增长速率的增长不是呈线性关系, 而是呈对数关系的.
