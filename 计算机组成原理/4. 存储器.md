
# 概述

## 存储器分类

按存储介质分类, 存储器可分为:
- 半导体存储器
- 磁表面存储器, 如: 磁盘, 磁带, 磁鼓
- 磁芯存储器, 用磁环存储数据, 磁环中穿过驱动线和读出线
- 光盘存储器

按存取方式, 存储器可分为:
- <font color=red><b>RAM</b></font> Random Access Memory, 随机存储器. 其中任何一个存储单元的内容都可以随机存取, 存取时间与存储单元的物理位置无关. RAM又分为SRAM(静态)和DRAM(动态). SRAM利用触发器寄存, DRAM利用电容寄存.
- <font color=red><b>ROM</b></font> Read Only Memory, 派生出PROM, EPROM, EEPROM. 后续发展出Flash Memory

另外还有串行访问存储器, 在读写操作室, 需要按照物理位置先后顺序进行寻址. 例如: 磁带. 磁盘也属于部分串行访问的存储器.


按在计算机中的作用分类, 可分为:
- <font color=red><b>主存</b></font>: 可以直接与CPU交换信息.
- <font color=red><b>辅存</b></font>: 不直接与CPU交换信息, 用于存放暂时不用的程序和数据.
- <font color=red><b>缓存</b></font>: 用在两个速度不同的部件之间起缓冲, 例如CPU和主存之间.

时至今日, 存储器的分类与作用为:

主存: DRAM
辅存: Flash Memory, 磁盘
缓存: SRAM

存储器的层次结构为:

$$
\begin{array}{c}
寄存器 \\
\Downarrow \\
缓存 \\
\Downarrow \\
主存 \\
\Downarrow \\
辅存
\end{array}
$$

越下层的存储器速度越慢, 容量更大, 成本更高.

理论上CPU可以直接和主存进行数据交换, 但是几乎从不这么做. 
现代计算机的CPU都是通过多级Cache获取数据, 而不会直接访问主存, 这是由于访问主存速度很慢, 可能会影响上百个CPU时钟周期.

主存和缓存之间的数据调动是硬件自动完成的, 对程序员透明.

<font color=red><b>MMU</b></font>通常在CPU与主存之间, 其核心职能为**虚拟内存管理**. 负责转换虚拟地址空间和物理地址空间: 
1. 地址翻译: 根据页表将虚拟地址翻译成物理地址. 使每个进程都认为自己独占一整片内存空间, 但实际可以映射到不同物理页.
2. 权限检查
3. 页异常管理

虚拟内存是围绕**页**展开动作的. 页是虚拟地址空间与物理地址空间映射的最小块. 
页表记录了虚拟页和物理页的映射关系.
常见页大小为4KB.

程序始终访问虚拟地址, 真实物理地址对程序透明. 每一次程序对数据的访问, MMU都会介入地址翻译.
现代CPU会在MMU内放一个小Cache (Translation Lookaside Buffer, TLB), 若命中, 则可以直接跳过页表查询.
对于CPU的一次数据访问, MMU会:
1. 查询 TLB, 若命中则直接得到物理地址.
2. Cache查找
3. DRAM查找
4. Flash查找


# 主存

主存的MDR通常设计为与CPU机器字长相等宽度. MAR通常设计为和地址总线宽度相等.

MDR和MAR都在CPU内部, 现代CPU通过Address Generation Unit和Load/Store Buffer取代了MDR和MAR.

现代主存使用<font color=red><b>DDR SDRAM</b></font>. 抽象的MAR和MDR之后, 输入到内存控制器中, 由内存控制器, 通过DDR PHY连接到内存.

内存上有被动逻辑执行单元, 用来译码地址, 解析命令, 对存储单元进行操作.

SRAM是使用触发器电路的存储结构.

DRAM是使用电容的存储结构. 由于电容中的电荷会消失, 因此DRAM需要进行刷新, 来保证数据的存储. 刷新周期通常为几ms至几百ms.
DRAM有三种刷新方式:
- 集中刷新: 在规定的一个刷新周期内, 对全部存储单元集中一段时间进行逐行刷新. 刷新过程中需要停止读/写操作. 不能进行读/写的时间称为访存死区, 所占比率称为死时间率.
- 分散刷新: 将每一个存取周期均划分成读写阶段和刷新阶段, 在刷新阶段对存储芯片进行刷新. 没有死区, 但是会延长存取周期, 造成浪费.
- 异步刷新: 按行数将刷新动作平分到整个刷新周期, 对于每一段来说是集中刷新, 对于整体来说是分散刷新. 将刷新安排在CPU指令译码阶段, 避免死区问题.

TTL和CMOS的主要区别:
TTL的核心器件是BJT, 是电流控制型器件, 需要电阻限制电流, 功耗较大.
CMOS的核心器件是MOSFET, 是电压控制型器件, 几乎不需要电流, 功耗极低.

PROM在每位存储单元内有熔丝, 熔丝断与未断用于存储数据.

EPROM和EEPROM是通过浮动栅型MOSFET, 利用浮动栅实现0和1的存储. 浮动栅被绝缘层隔绝, 存储的电荷不能轻易移动, 不会轻易消失.

Flash 也使用浮动栅型 MOSFET 存储数据. Flash 的擦除是通过块擦除的模式.
NOR Flash 每个存储单元有独立的位线, 可以随机访问单个字节. NAND Flash 按块读写.
Flash 通过精确控制浮动栅中电荷量的不同, 区分出多个电压阈值区间, 从而在一个单元中存储多位信息, 即: SLC, MLC, TLC, QLC.


## 存储器与CPU的连接

由于单片存储芯片容量有限, 因此通常需要将若干存储芯片组合, 称为存储容量的扩展, 分为位扩展与字扩展.
- 位扩展: 增加存储字长, 例如 2片 1K×4 bit 的芯片构成 1K×8 bit 的存储器.
- 字扩展: 增加存储器字数量, 例如 2片 1K×8 bit 的芯片构成 2K×8 bit 的存储器.
- 字, 位扩展: 组合以上两种方式.

存储器与CPU连接包括地址线, 数据线, 控制线(读/写命令线, 片选线)

## 汉明码

汉明码是一种检错纠错的编码, 具有1位纠错能力.

<font color=red><b>汉明距离</b></font>是两个等长传对应位置不同字符的数量.
<font color=red><b>最小码距</b></font>是编码中任意两个有效码字之间的最小汉明距离.
有如下公式:

$$
d-1 = e+c
\quad (e\geq c)
$$

其中 $d$ 是最小码距, $e$ 是检错位数, $c$ 是纠错位数. 
增加冗余码可以提高最小码距, 提升纠错能力, 会降低码率. 
将上述公式变换:

$$
\begin{array}{l}
要检测\ e\ 个错误: d \geq e + 1 \\
要纠正\ c\ 个错误: d \geq 2c + 1
\end{array}
$$

汉明码通常表示为 $(n,k)$ 码, 其中:
- $k$ : 信息位的位数, 即原始数据长度
- $r$ : 校验位的位数
- $n$ : 总长度, $n = k + r$ 

对于纠正 1 bit 错误, 需要的校验位数 $r$ 必须满足 $2^r \geq k+r+1$ 或 $2^r \geq n + 1$ .

汉明码被设计为能够判断数据中的哪一位出现错误. 对于总长为n的码字, 错误可能发生在n个位置中的任意一个, 也可能不发生错误, 即一共 $n+1$ 种状态. 

汉明码的核心思想是用 $r$ 个校验位, 生成一个 $r$ 位的二进制数, 这个数即错误地址.

由此可见, 对于能够表示错误发生位的前提是, $2^r$ 一定大于等于总码字长 $n+1$ .

例如: 校验位数 $r = 3$ , 则:
- $0b000 = 0$ 表示无错误.
- $0b001 = 1$ 表示第 1 位出错.
- $\cdots$
- $0b111 = 7$ 表示第 7 位出错.

可见, 当 $r=3$ 时, 最多可以处理7位数据的纠错需求.

7 位数据中, 去除校验位的 3 位, 剩余的 4 位是原本的实际数据位.

在以上基础前提要求下, 汉明码通过精心安排校验位的检测范围, 巧妙地做到了伴随式 $S$ 的值与错误发生的位序号完全一致.

编码规则为:
- 将 $r$ 个校验位 $P_1, P_2, \cdots, P_r$ 放在位序号 $1,2,4,\cdots,2^{r-1}$ 上 (从 $1$ 开始记) . 
- 将每个校验位 $P_i$ 定义为对所有位序号中包含 $2^{i-1}$ 的位进行校验 (通常是奇偶校验) .

